% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MarkovitzRRR.R, R/utils.R
\name{MarkovitzRRR}
\alias{MarkovitzRRR}
\alias{PlotMarkovitzRRRObjective}
\title{Compute Markovitz Optimal Portfolios via Reduced Rank Regression (RRR)}
\usage{
MarkovitzRRR(
  returns,
  initial_solution = matrix(0, 0, 0),
  lambda1 = 0,
  lambda2 = 0,
  penalty_type = "d",
  step_size_type = "d",
  step_size_constant = -1,
  max_iter = 10000,
  tolerance = 0,
  check_arguments = TRUE
)

PlotMarkovitzRRRObjective(results)
}
\arguments{
\item{returns}{\verb{n_observations x n_returns}-dimensional matrix of centred(!)
test asset excess returns.}

\item{initial_solution}{\verb{n_returns x n_returns}-dimensional matrix of initial
hedging weights. If it is an empty matrix, then it is set to a hollow matrix
(a matrix with zero diagonal) with \code{1/N} as off-diagonal elements.
Default is \code{matrix(0, 0, 0)}.}

\item{lambda1}{a number indicating the penalty parameter associated
with the Nuclear penalty \verb{lambda1 * ||R * X||_*} or \verb{lambda1 * ||X||_*};
see \code{penalty_type}. Default is \code{0}.
If it is less than or equal to zero, optimization is carried on without this
penalty.}

\item{lambda2}{a number indicating the penalty parameter associated
with the Ridge penalty \verb{lambda2 * ||X||_F^2}.
If it is less than or equal to zero, optimization is carried on without this
penalty. Default is \code{0}.}

\item{penalty_type}{character indicating the type of penalty function: \code{'d'}
for default, i.e., penalty given by \verb{||RX||_*}; \code{'a'} for alternative, i.e.,
penalty given by \verb{||X||_*}. Default is \code{'d'}.}

\item{step_size_type}{character indicating the type of step size:
\code{'d'} for default, i.e., not summable vanishing:
\code{step_size_constant / sqrt(iter + 1)};
\code{'s'} for square summable but not summable: \code{step_size_constant / (iter + 1)};
\code{'l'} for constant step length: \verb{step_size_constant / ||subgradient||_F}.
\code{'p'} for modified Polyak:
\verb{(step_size_constant + objective_iter - min\{objective_k | k=0,...,iter\}) / ||subgradient)||_F}.
\code{'c'} for constant step size: \code{step_size_constant}.
Default is \code{'d'}.}

\item{step_size_constant}{numeric constant determining the step size.
If it is zero or negative, then it is internally set to
\code{2./(min(sv(R))^2 + max(sv(R))^2 + lambda2)},
where \code{sv} denotes singular values. Default is \code{0}.}

\item{max_iter}{numeric solver parameter indicating the maximum number of
iterations. Default is \code{10000}.}

\item{tolerance}{numeric tolerance check for the Frobenious norm
of successive solutions \verb{||X_k+1 - X_k||_F / N}.
If \code{tolerance > 0}, then the solver is stopped when \verb{||X_k+1 - X_k||_F / N <= tolerance}.
If \code{tolerance <= 0}, no check is performed. Default is \code{0}.}

\item{check_arguments}{boolean \code{TRUE} if you want to check function arguments;
\code{FALSE} otherwise. Default is \code{TRUE}.}

\item{results}{list containing a numeric vector \code{objective} with the
markovitzRRR objective function values at each iteration.}
}
\value{
a list containing: the optimal solution in \verb{$solution}; the optimal
value in \verb{$objective}; the optimal portfolio weights in \verb{$weights}; the number
of iterations in \verb{$iterations};
the solver status check (indicating if the objective value decreased from the
value at the initial value) in \verb{$is_improved}; the solver status
check (indicating if the objective value at the last solution equal to
the value at the best solution?) in \verb{$is_converged}.
}
\description{
Computes Markovitz optimal portfolios via Reduced Rank Regression
approach by solving the optimization problem:
minimize_X {0.5 ||R - RX||\emph{F^2 + lambda1 ||RX||}* + lambda2/2 ||X||_F^2 | diag(X) = 0}
or the alternative
minimize_X {0.5 ||R - RX||\emph{F^2 + lambda1 ||X||}* + lambda2/2 ||X||_F^2 | diag(X) = 0},
where ||.||\emph{F denotes the Frobenious norm and ||.||}* the Nuclear norm.
Then, optimal weights are given by:
\code{w = diag(Var[E])^(-1) * (I - X)}, where \code{E} is the residual in the regression
R = RX + E.

Plots the  MarkovitzRRR objective function value at each iteration
}
\examples{
# Example usage with real data
returns = markovitzRRR::returns[1:50,-1]
result = MarkovitzRRR(returns, lambda1 = 0.1, lambda2 = 0.1)

}
